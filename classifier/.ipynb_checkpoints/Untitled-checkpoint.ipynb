{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "collective-george",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2\n",
    "import time\n",
    "import random\n",
    "import numpy as np\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "import torchvision.transforms as T\n",
    "from torchvision.utils import make_grid\n",
    "from torchvision.models import resnet50\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from PIL import Image\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "consistent-uruguay",
   "metadata": {},
   "outputs": [],
   "source": [
    "DIR_TRAIN = \"./data/train\"\n",
    "DIR_TEST = \"./data/test1\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "complex-eating",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['cat.0.jpg', 'cat.1.jpg', 'cat.10.jpg', 'cat.100.jpg', 'cat.1000.jpg']\n",
      "['1.jpg', '10.jpg', '100.jpg', '1000.jpg', '10000.jpg']\n"
     ]
    }
   ],
   "source": [
    "imgs = os.listdir(DIR_TRAIN) \n",
    "test_imgs = os.listdir(DIR_TEST)\n",
    "\n",
    "print(imgs[:5])\n",
    "print(test_imgs[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "headed-business",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_train_transform():\n",
    "    return T.Compose([\n",
    "        T.RandomHorizontalFlip(p=0.5),\n",
    "        T.RandomRotation(15),\n",
    "        T.RandomCrop(204),\n",
    "        T.ToTensor(),\n",
    "        T.Normalize((0, 0, 0),(1, 1, 1))\n",
    "    ])\n",
    "    \n",
    "def get_val_transform():\n",
    "    return T.Compose([\n",
    "        T.ToTensor(),\n",
    "        T.Normalize((0, 0, 0),(1, 1, 1))\n",
    "    ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "thrown-characteristic",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CatDogDataset(Dataset):\n",
    "    \n",
    "    def __init__(self, imgs, class_to_int={'cat':0, 'dog':1}, mode = \"train\", transforms = None):\n",
    "        \n",
    "        super().__init__()\n",
    "        self.imgs = imgs\n",
    "        self.class_to_int = class_to_int\n",
    "        self.mode = mode\n",
    "        self.transforms = transforms\n",
    "        \n",
    "    def __getitem__(self, idx):\n",
    "        \n",
    "        image_name = self.imgs[idx]\n",
    "        \n",
    "        ### Reading, converting and normalizing image\n",
    "        #img = cv2.imread(DIR_TRAIN + image_name, cv2.IMREAD_COLOR)\n",
    "        #img = cv2.resize(img, (224,224))\n",
    "        #img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB).astype(np.float32)\n",
    "        #img /= 255.\n",
    "        img = Image.open(DIR_TRAIN + image_name)\n",
    "        img = img.resize((224, 224))\n",
    "        \n",
    "        if self.mode == \"train\" or self.mode == \"val\":\n",
    "        \n",
    "            ### Preparing class label\n",
    "            label = self.class_to_int[image_name.split(\".\")[0]]\n",
    "            label = torch.tensor(label, dtype = torch.float32)\n",
    "\n",
    "            ### Apply Transforms on image\n",
    "            img = self.transforms(img)\n",
    "\n",
    "            return img, label\n",
    "        \n",
    "        elif self.mode == \"test\":\n",
    "            \n",
    "            ### Apply Transforms on image\n",
    "            img = self.transforms(img)\n",
    "\n",
    "            return img\n",
    "            \n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.imgs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "conditional-sunglasses",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_imgs, val_imgs = train_test_split(imgs, test_size = 0.25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "mexican-verification",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = CatDogDataset(train_imgs, mode = \"train\", transforms = get_train_transform())\n",
    "val_dataset = CatDogDataset(val_imgs, mode = \"val\", transforms = get_val_transform())\n",
    "test_dataset = CatDogDataset(test_imgs, mode = \"test\", transforms = get_val_transform())\n",
    "\n",
    "train_data_loader = DataLoader(\n",
    "    dataset = train_dataset,\n",
    "    num_workers = 4,\n",
    "    batch_size = 16,\n",
    "    shuffle = True\n",
    ")\n",
    "\n",
    "val_data_loader = DataLoader(\n",
    "    dataset = val_dataset,\n",
    "    num_workers = 4,\n",
    "    batch_size = 16,\n",
    "    shuffle = True\n",
    ")\n",
    "\n",
    "test_data_loader = DataLoader(\n",
    "    dataset = test_dataset,\n",
    "    num_workers = 4,\n",
    "    batch_size = 16,\n",
    "    shuffle = True\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "hispanic-camcorder",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "quiet-converter",
   "metadata": {},
   "outputs": [],
   "source": [
    "def accuracy(preds, trues):\n",
    "    \n",
    "    ### Converting preds to 0 or 1\n",
    "    preds = [1 if preds[i] >= 0.5 else 0 for i in range(len(preds))]\n",
    "    \n",
    "    ### Calculating accuracy by comparing predictions with true labels\n",
    "    acc = [1 if preds[i] == trues[i] else 0 for i in range(len(preds))]\n",
    "    \n",
    "    ### Summing over all correct predictions\n",
    "    acc = np.sum(acc) / len(preds)\n",
    "    \n",
    "    return (acc * 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "legislative-somerset",
   "metadata": {},
   "outputs": [],
   "source": [
    "#for images, labels in train_data_loader:\n",
    "    #print('xd')\n",
    "    #fig, ax = plt.subplots(figsize = (10, 10))\n",
    "    #ax.set_xticks([])\n",
    "    #ax.set_yticks([])\n",
    "    #ax.imshow(make_grid(images, 4).permute(1,2,0))\n",
    "    #break\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "three-tiffany",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading: \"https://download.pytorch.org/models/resnet50-19c8e357.pth\" to C:\\Users\\artiz/.cache\\torch\\hub\\checkpoints\\resnet50-19c8e357.pth\n"
     ]
    },
    {
     "ename": "ImportError",
     "evalue": "IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-21-33ba132f1af5>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mmodel\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mresnet50\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpretrained\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;31m# Modifying Head - classifier\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m model.fc = nn.Sequential(\n",
      "\u001b[1;32mc:\\users\\artiz\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\torchvision\\models\\resnet.py\u001b[0m in \u001b[0;36mresnet50\u001b[1;34m(pretrained, progress, **kwargs)\u001b[0m\n\u001b[0;32m    298\u001b[0m         \u001b[0mprogress\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mbool\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mIf\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdisplays\u001b[0m \u001b[0ma\u001b[0m \u001b[0mprogress\u001b[0m \u001b[0mbar\u001b[0m \u001b[0mof\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mdownload\u001b[0m \u001b[0mto\u001b[0m \u001b[0mstderr\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    299\u001b[0m     \"\"\"\n\u001b[1;32m--> 300\u001b[1;33m     return _resnet('resnet50', Bottleneck, [3, 4, 6, 3], pretrained, progress,\n\u001b[0m\u001b[0;32m    301\u001b[0m                    **kwargs)\n\u001b[0;32m    302\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\artiz\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\torchvision\\models\\resnet.py\u001b[0m in \u001b[0;36m_resnet\u001b[1;34m(arch, block, layers, pretrained, progress, **kwargs)\u001b[0m\n\u001b[0;32m    260\u001b[0m     \u001b[0mmodel\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mResNet\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mblock\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlayers\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    261\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mpretrained\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 262\u001b[1;33m         state_dict = load_state_dict_from_url(model_urls[arch],\n\u001b[0m\u001b[0;32m    263\u001b[0m                                               progress=progress)\n\u001b[0;32m    264\u001b[0m         \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mload_state_dict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstate_dict\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\artiz\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\torch\\hub.py\u001b[0m in \u001b[0;36mload_state_dict_from_url\u001b[1;34m(url, model_dir, map_location, progress, check_hash, file_name)\u001b[0m\n\u001b[0;32m    522\u001b[0m             \u001b[0mr\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mHASH_REGEX\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msearch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfilename\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# r is Optional[Match[str]]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    523\u001b[0m             \u001b[0mhash_prefix\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mr\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgroup\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0mr\u001b[0m \u001b[1;32melse\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 524\u001b[1;33m         \u001b[0mdownload_url_to_file\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0murl\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcached_file\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhash_prefix\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mprogress\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mprogress\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    525\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    526\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0m_is_legacy_zip_format\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcached_file\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\artiz\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\torch\\hub.py\u001b[0m in \u001b[0;36mdownload_url_to_file\u001b[1;34m(url, dst, hash_prefix, progress)\u001b[0m\n\u001b[0;32m    411\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mhash_prefix\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    412\u001b[0m             \u001b[0msha256\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mhashlib\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msha256\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 413\u001b[1;33m         with tqdm(total=file_size, disable=not progress,\n\u001b[0m\u001b[0;32m    414\u001b[0m                   unit='B', unit_scale=True, unit_divisor=1024) as pbar:\n\u001b[0;32m    415\u001b[0m             \u001b[1;32mwhile\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\artiz\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\tqdm\\notebook.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    233\u001b[0m         \u001b[0munit_scale\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m1\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0munit_scale\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mTrue\u001b[0m \u001b[1;32melse\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0munit_scale\u001b[0m \u001b[1;32mor\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    234\u001b[0m         \u001b[0mtotal\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtotal\u001b[0m \u001b[1;33m*\u001b[0m \u001b[0munit_scale\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtotal\u001b[0m \u001b[1;32melse\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtotal\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 235\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcontainer\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstatus_printer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfp\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtotal\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdesc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mncols\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    236\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcontainer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpbar\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    237\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mdisplay_here\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\artiz\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\tqdm\\notebook.py\u001b[0m in \u001b[0;36mstatus_printer\u001b[1;34m(_, total, desc, ncols)\u001b[0m\n\u001b[0;32m    110\u001b[0m         \u001b[1;31m# Prepare IPython progress bar\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    111\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mIProgress\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m  \u001b[1;31m# #187 #451 #558 #872\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 112\u001b[1;33m             raise ImportError(\n\u001b[0m\u001b[0;32m    113\u001b[0m                 \u001b[1;34m\"IProgress not found. Please update jupyter and ipywidgets.\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    114\u001b[0m                 \u001b[1;34m\" See https://ipywidgets.readthedocs.io/en/stable\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mImportError\u001b[0m: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html"
     ]
    }
   ],
   "source": [
    "model = resnet50(pretrained = True)\n",
    "\n",
    "# Modifying Head - classifier\n",
    "\n",
    "model.fc = nn.Sequential(\n",
    "    nn.Linear(2048, 1, bias = True),\n",
    "    nn.Sigmoid()\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
